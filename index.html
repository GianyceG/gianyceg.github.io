<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Time Series Project</title>
  <style>
    /* Simple tab styles */
    .tab {
      overflow: hidden;
      background-color: #f1f1f1;
    }

    .tab button {
      background-color: inherit;
      border: none;
      outline: none;
      cursor: pointer;
      padding: 14px 16px;
      transition: 0.3s;
      font-size: 17px;
    }

    .tab button:hover {
      background-color: #ddd;
    }

    .tab button.active {
      background-color: #ccc;
    }

    .tabcontent {
      display: none;
      padding: 6px 12px;
      border-top: none;
    }

    .tabcontent.active {
      display: block;
    }
  </style>
    <!-- Include MathJax for LaTeX rendering -->
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  
</head>
<body>

  <h1>Explorations of Time Series Analysis Techniques and Forecasting Methods on Real-World Applications</h1>

  <!-- Tab buttons -->
  <div class="tab">
    <button class="tablinks" onclick="openTab(event, 'LitReview')" id="defaultOpen">Literature Reviews</button>
    <button class="tablinks" onclick="openTab(event, 'Intro')">Introduction</button>
    <button class="tablinks" onclick="openTab(event, 'Methods')">Methods</button>
    <button class="tablinks" onclick="openTab(event, 'References')">References</button>
  </div>

  <!-- Tab content for Literature Reviews -->
  <div id="LitReview" class="tabcontent">
    <h2>Literature Reviews</h2>
    <p>My semester project focuses on exploring time series analysis using ARIMA/SARIMA and Bayesian models to forecast and analyze the spread of COVID-19 and CO2 emissions in Mauna Loa, Hawaii. Below are the literature reviews I have completed, highlighting the methods and techniques applied in my research.</p>
    <ul>
      <li><a href="Capstone_Paper_Review_Literature_Review__Week1.pdf">Week 1 Review</a></li>
      <li><a href="https://github.com/GianyceG/gianyceg.github.io/blob/main/Capstone_Paper_Review_Literature_Review__2_%20(1).pdf">Week 2 Review</a></li>
      <li><a href="https://github.com/GianyceG/gianyceg.github.io/blob/main/Capstone_Paper_Review_Literature_Review__3_%20(1).pdf">Week 2 Paper 2 Review</a></li>
      <li><a href="https://github.com/GianyceG/gianyceg.github.io/blob/main/Capstone_Paper_Review_Literature_Review__4_%20(1).pdf">Week 3 Review</a></li>
    </ul>
  </div>

<!-- Tab content for Introduction -->
  <div id="Intro" class="tabcontent">
<img src="images/Screenshot%202024-10-14%20212930.png" alt="Time Series Forecast" width="600" height="300">
<p><em>Source: <a href="https://towardsdatascience.com/an-introduction-to-time-series-analysis-with-arima-a8b9c9a961fb" target="_blank">An Introduction to Time Series Analysis with ARIMA, Towards Data Science</a></em></p>
    <h2>Introduction</h2>
    <p>Anything that is observed sequentially over time is a time series. In the data, I will look at regular intervals of time. Time series forecasting is a statistical method used to predict future values based on past results. The simplest models focus solely on the variable being forecast, ignoring external factors like marketing efforts or economic shifts, and instead extrapolating existing trends and seasonality. Specifically in this capstone, I will be exploring univariate models ARIMA/SARIMA and the Bayesian STS.</p>
    <p>The use of time series analysis gained recognition since 1970 when the Box-Jenkins method popularized ARIMA models to find the best fit of different time series models based on past data. However, the concept of analyzing sequential data over time is not new. As the world increasingly embraces data-driven solutions to forecast future industry outcomes, time series analysis has become vital in numerous fields. </p>
<p>Currently, efforts to perfect the science of forecasting is important as the higher the accuracy of a time series based on past data and events, the more essential the tool becomes for modern organizations as accurate forecasts support decision-making across various timeframes—whether short-term, medium-term, or long-term, depending on the specific application. Key considerations in forecasting include seasonality, trends, and external fluctuations, which play a significant role in shaping predictions. These specifically will be explored more as I deal with the data sets of this project. These forecasts are integral for planning, resource allocation, and adjusting strategies in response to upcoming movements.</p>
  <p>The main goal of my paper is to explore and discuss the concept and use real life datasets in order to see how time series analysis can use its historical data and leverage practical and meaningful conclusions. In this paper, we will also be discussing any possible limitations that the different time series models have and what some suggestions are to improve our predictions and possibly overcome these limitations. <p>
    <p>In this capstone, I will explore the Johns Hopkins CSSEGISandData COVID-19 Repository, which tracks global COVID-19 cases and Our World in Data (OWID), which provides comprehensive COVID-19 datasets across various indicators datasets to test the univariate models ARIMA/SARIMA and Bayesian STS. Using the same model structures, I will also be exploring the Forecasting CO2 Emissions in Mauna Loa, Hawaii. This dataset is provided by the Global Monitoring Laboratory within NOAA. The goal of this exploration is to apply time series analysis to forecast the future spread of COVID-19, seeing which models are the strongest to do such a task, and to use those same models to appropriately forecast the increasing trend of the CO2 emission rates. These two different datasets and applications are to show the strength in forecasting in multiple real-life situations. This is important in data science and statistics, particularly in public health and global policy as creating accurate forecasts can allow policymakers a better direction on what should be applied and when. </p>
    <p>To achieve the goals of my capstone, ARIMA/SARIMA will be used for capturing linear trends and seasonal effects, and Bayesian STS for incorporating uncertainty and providing probabilistic forecasts. The project will begin with an exploratory data analysis (EDA) to visualize the time series data, identify patterns, and check for seasonality or trends. After cleaning and preprocessing the data, I will test both models using Python on the COVID-19 and CO2 datasets. The results will then be compared to assess which approach yields the most accurate and insightful forecasts. </p>
<h2>Time Series Forecasting Models</h2>
  <p>In different papers and studies, it is easy to see that there are a multitude of models to explore and chose from, depending on what is being questioned or asked from by the researcher and data. Most of the models can be seen following into different categories. Traditional statistical modeling, which includes a moving average, exponential smoothing, and autoregressive (ARIMA). These are seen as linear functions taking past observations to make sound predictions. Second category of model type is nonlinear models. This will not be covered in my project, but the main difference lies in the complexity and non-proportional relationships in the data. An example of this can be LSTM, ANN, NAR models. The second main model type that I will be covering is the Bayesian Structural Time Series (BSTS). This model type is considered linear, since it relies on the state-space models, but can handle much more complexity such as trend, seasonality, and regression components. So, although it is linear, the approach is more flexible by adding prior distributions allowing for uncertainty estimations. In this capstone, these two ARIMA/SARIMA and Bayesian STS will be explore in depth.  </p>
   
<h3>ARIMA Model</h3>
<p>To begin, throughout this project I will be utilizing the ARIMA model as a traditional method of time series forecasting. ARIMA stands for Autoregressive integrated moving average and it predicts future values with past values. It utilizes lagged moving averages to smooth the time series data. The ARIMA model is a univariate model that can be broken down into two different models, AR and MA, which will be define below.</p>
<p>The ARIMA model is defined by the parameters \( (p, d, q) \), where:</p>
<ul>
  <li>\( p\) is the number of lag observations (autoregressive terms).</li>
  <li>\( d\) is the number of times the data must be differenced to make it stationary.</li>
  <li>\( q\) is the number of lagged forecast errors (moving average terms) <a href="#ref1">[1]</a>.</li>
</ul>

<p>The ARIMA model is composed of two submodels, the AR (Autoregressive) and the MA (Moving Average) model, described mathematically as follows:</p>
<p>\[Y(AR)_t = \alpha + \beta_1 Y(AR)_{t-1} + \beta_2 Y(AR)_{t-2} + \cdots + \beta_p Y(AR)_{t-p}\] (1)</p>
<p>where \( Y(AR)_t \) are the lags of the series, \( \beta \) are the lag coefficients estimated by the model, and \( \alpha \) is the model’s intercept term.</p>
<p>\[Y(MA)_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}\] (2)</p>
<p>where \( Y(MA)_t \) depends only on the lagged forecast errors, \( \theta \) are the parameters of the model, and \( \epsilon \) are unrelated error terms.</p>
<p>The mathematical expression of the ARIMA model, as a combination of AR and MA models, is:</p>
<p>\[Y_t = \alpha + \sum_{i=1}^{p} \beta_i Y_{t-i} + \epsilon_t - \sum_{j=1}^{q} \theta_j \epsilon_{t-j}\] (3)</p>
<p>Where \( Y_t \) and \( \epsilon_t \) represent the time series and the random error at time \( t \), \( \beta \) and \( \theta \) are the coefficients of the model.</p>
<p>When estimating the \( p\) and \( q\) parameters of the AR and the MA models, plots from the ACF function and the PACF functions are used. Just to summarize, the autocorrelation function, ACF, is a function that shows the correlation between the observed of the \(t \) time and the observation at the previous times. This function indicates the autocorrelation coefficient, which is the measurement of the correlation between observations at different times. PACF, or partial autocorrelation function differs because it is the correlation between two random variables after the influence of confounding variable is removed <a href="https://iopscience.iop.org/article/10.1088/1755-1315/235/1/012097/pdf" target="_blank">[7]</a>.</p>

<img src="images/Screenshot 2024-10-15 004734.png" alt="Stationary_Example" width="600" height="300">
<p><em>Source: <a href="https://www.researchgate.net/publication/348592737/figure/fig3/AS:981645804970018@1611054006754/Examples-for-stationary-and-non-stationary-time-series.png" target="_blank">Classification of Time Series</a></em></p>

<p>Prior to finding the ACF/PACF, it is obligated for us to know if the data that is obtained is stationary or nonstationary. This is important because if the data is not stationary, the data cannot perform the ARIMA model accurately. Therefore, in order to determine if the model is stationary, it can be visualized or the Dickey-Fuller Test can be performed to determine the classification of the time series data.</p>
<p>When differencing is applied and observed, the \(p\) order deals with the AR model and it is based on the significant spikes from the PACF plot. The MA model, \(q\) order is determined if the ACF plots have sharp cut-off after lags. If there has been any differencing applied to the model, \(d\) is determined by the order of the differencing (i.e. how many times the differencing has been applied).   </p>
<p>After the strongest combination of the \( (p, d, q) \) have been selected, it is possible to then run the ARIMA model and see the results. At times, it can be difficult to physically pick out the correct combination. If this becomes the case, there are machine learning approaches to choose the appropriate orders.</p>

<h2>Bayesian Structural Time Series Model</h2>
  
<h2>Bayesian Structural Time Series Model</h2>

<p> 
  Fundamentally, this theorem is unique from ARIMA due to differences in the interpretation of what “probability” means. 
  We will explore criticisms later, but it is important to remember this distinction when understanding the model differences. 
  Bayesian inference is a method of statistical inference where available knowledge about parameters in a statistical model 
  is updated with information from observed data. 
  <a href="https://www.nature.com/articles/s43586-020-00001-2" target="_blank">A Guide to Bayesian Inference</a>. 
</p>

<p>
  Assume that you have a sample of observations \( y_1, \dots, y_n \) of a random variable \( Y \sim f(y \mid \theta) \), 
  where \( \theta \) is a parameter for the distribution. Here consider \( \theta \) to be a random variable too. 
  Following Bayes Theorem (its continuous version), the following is true:
</p>

\[ f(\theta \mid y) = \frac{f(y \mid \theta) f(\theta)}{f(y)} = \frac{f(y \mid \theta) f(\theta)}{\int f(y \mid \theta) f(\theta) \, d\theta} \]

<ul>
  <li>The function \( f(y \mid \theta) \) is called the <strong>likelihood</strong>.</li>
  <li>\( f(\theta) \) is the <strong>prior distribution</strong> of \( \theta \).</li>
</ul>

<p>
  Note that \( f(y) \) does not depend on \( \theta \) (just on the data), therefore it can be considered as a "normalizing constant". 
  In addition, it is often the case that the integral above is not easy to compute. Nevertheless, it is enough to consider the relation:
</p>

\[ f(\theta \mid y) \propto \text{likelihood} \times \text{prior} \]

<p>(Here \( \propto \) denotes the proportionality relation.)</p>

<p> Now, for Bayesian Structural Time-Series Models, the time series can be broken down into four basic models depending on the following: 
  a level, a local trend, seasonal impacts, and an error term. Structural Time Series models can be defined by the following:</p>

<div class="equation">
  <div> \[ y_t = Z_t^T \alpha_t + \varepsilon_t \] </div>
  <div class="equation-number">(4)</div>
</div>

<div class="equation">
  <div> \[ \alpha_{t+1} = T_t \alpha_t + R_t \eta_t \] </div>
  <div class="equation-number">(5)</div>
</div>

<p> Equation (4) and Equation (5) represent the structure of the model. Equation (4) is trying to understand the 
  distribution of the \( Y_t \)’s of the data, while Equation (5) is closely related to understanding the distribution 
  of the parameters. It provides the evolution model for the parameters and how they change over time. 
  Because the vector evolves through randomness, it describes the distribution of the hidden parameters at the next step. 
  This is crucial because for Bayesian inference to hold, updating the beliefs of the parameters helps incorporate 
  both the priors and the observed data.</p>

<h2>Criticism and Limitations</h2>
  <p> The key distinction between the ARIMA and Bayesian methods lies in their underlying theoretical perspectives: frequentist vs. Bayesian. In the frequentist approach (as used in ARIMA models), parameters are treated as fixed values that do not change once estimated. The data is analyzed under the assumption that these parameters have unique, fixed points. </p>
  <p> In contrast, the Bayesian approach views parameters as random variables that can evolve over time, with uncertainty captured through prior distributions. This flexibility allows the Bayesian method to incorporate prior knowledge about the parameter’s movement and update these beliefs as new data becomes available, resulting in what is known as posterior distributions. </p>
  <p> This difference introduces a potential limitation: if the prior distribution is inaccurate or misinformed, it can negatively affect the model’s output. While prior information can enhance predictions, it can also become a burden if the assumptions are flawed or if prior knowledge conflicts with new observations. Therefore, Bayesian models offer both advantages and risks: they excel when reliable prior knowledge is available but can be inaccurate if the priors introduce bias into the model. </p>
  <p> Next, time series analysis inherently faces criticism because it attempts to predict the future—data that has not yet materialized—with as much certainty as possible. When practicing time series forecasting, it is crucial to not only critique the model’s inference but also incorporate evaluation methods into the decision-making process, given the inherent uncertainty of projections. </p>
  <p> While cross-validation techniques are still applicable and recommended for time series models, specific approaches such as leave-one-out (LOO) cross-validation can pose challenges. For time series, LOO can be problematic when the goal is to estimate predictive performance for future time points, as removing an observation disrupts the temporal dependencies in the data. This is particularly problematic from a Bayesian perspective, where each time point informs the next. Ignoring these dependencies undermines the theoretical foundation of time series models, which rely on the structure of sequential observations. </p>

</div>
  
 <!-- Tab content for Methods for COVID-19 -->
  <div id="Methods" class="tabcontent">
    <h2>Methods </h2>
    <p>My project explores time series forecasting using two distinct datasets: one focused on COVID-19 data and the other on the NOAA Mauna Loa CO2 emission dataset.  I will apply my models to both datasets and compare their forecasting strengths to one another. Then, I will generate an overall summary on strengths, weaknesses, and limitations that were faced throughout my project. </p>

    <h2>Johns Hopkins COVID-19 Exploration </h2>
    <p>This part of the project uses time series forecasting on the COVID-19 dataset from the Johns Hopkins CSSEGISandData Repository and Our World in Data (OWID), with an emphasis on modeling the data using ARIMA/SARIMA and Bayesian Structural Time Series (BSTS). AR and ARIMA models are univariate (single-variable) time series methods without trend or seasonal components, while other time series models, such as SARIMA, can capture multivariate series with trends and seasonal patterns. Within this capstone, I will show how the predictions will look when forecasted with ARIMA, SARIMA, and Bayesian STS. Then, I will compare my results, decide which is best suited for the COVID-19 dataset, and revisit the limitations of the models with the results of their applications. </p>
    <p> First, the data will be loaded into JupyterNotebook and processed with Python. Then, the data is already cleaned through the github repository CSSEGISandData.

    <h3>ARIMA Applied to Python</h3>
    <p>The key libraries utilized for processing my ARIMA model were <strong>Pandas</strong>, <strong>Matplotlib</strong>, and <strong>Statsmodels</strong>. I used <strong>Pandas</strong> extensively for data manipulation, including loading the dataset, converting date columns to datetime format, applying differencing to achieve stationarity, and other data preparation tasks. <strong>Matplotlib</strong> was instrumental in visualizing the time series, including plotting the original and differenced data, as well as visualizing the autocorrelation and forecast results. <strong>Statsmodels</strong> was used to fit the ARIMA model and provided essential tools for analyzing time series properties, such as plotting the partial autocorrelation function (PACF) and autocorrelation function (ACF), as well as fitting the model itself to make predictions.</p>

    <h4>Process</h4>
    <p>  I processed the data from the Johns Hopkins dataset. They had the data already prepared and cleaned, organized by the country, province, state, update, confirmed cases, and more variables. These are the ones I focused on. After loading the dataset into Jupyter Notebook, I am able to observe the columns and data. To explore the data, I begin by applying a rolling statistic over the dataset. This is to show the rolling window along the time series, and with ARIMA it is particularly of interest as it is the visualization of moving averages. These averages provide a smoothed representation of the data by averaging fluctuations. </p>
    <img src="images/Screenshot 2024-10-15 064846.png" alt="Rolling_Mean_STD" width="600" height="300">
    <p><em>Source: Rolling Mean and Rolling Standard Deviation over 7-day periods, showing the trend of confirmed COVID-19 cases in Florida (2020-2023).</em></p>

    <p>As we can see, the blue line of confirmed cases, or the cumulative data has small rigidness on the line. When the rolling mean was applied, it smoothed out the curve based on the 7-day rolling window. This averages out the daily changes to the data over a week at a time. Because the changes of the window size is low, the standard deviation line in green will appear low, indicating that the variations over that period are not significant. All this is applicable to our data as the nature of COVID-19’s spread tends to increase in a consistent matter over time, except as we can see in 2022-01, we had a significant spike. Aside from that, the rolling standard deviation proves that there is lower variability. </p>
    <p>As I am exploring and graphing the data, I made sure that the date and time variables were all formatted correctly and cleaned up any NaN values. Then, I begin the ARIMA process. Visually, the data appears to be stationary. This can be determined by the characteristics that it is trending upwards and has some sort of seasonality since there is a pattern with in the upward trend that appears to be relatively consistent. However, if I want to make sure I will approach by applying the Dickey-Fuller hypothesis testing. </p>
<ul>
    <li><strong>H0:</strong> The data is non-stationary.</li>
    <li><strong>H1:</strong> The data is stationary.</li>
</ul>
  <p> Due to the fact that my p-value was greater than 0.05, we fail to reject the null hypothesis, and therefore perform a first order differencing on the model. Which is then seen to be stationary under this hypothesis. Since this has now confirmed that the data is stationary, a first order differencing is now necessary to continue.<\p>
   <p> After applying differencing, the following graph is formulated. On this differenced graph of the data, the ADF test is reapplied. </p> 
    <li>Using the AIC function, I determined the most ideal ARIMA model parameters for (p,d,q).</li>
  <li>I fitted the model and checked the residuals for white noise.</li>
  <li>Developed a forecast for the next 30 days for the state of Florida.</li>
</ol>
    
    <p>My ARIMA Model:</p>
    <p>For this specific COVID-19 data and the model that I will end up generating, the following is the mathematical expression of my ARIMA model in general terms:</p>
    <p> \[Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \dots + \phi_5 Y_{t-5} + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \dots + \theta_5 \epsilon_{t-5} + \epsilon_t\] </p>
    <p>Where:</p>
    <ul>
    <li>\( Y_t \): The value of the time series at time \( t \) (in this case, the number of COVID-19 confirmed cases in Florida).</li>
    <li>\( c \): Constant term (intercept).</li>
    <li>\( \phi_i \) (\( i = 1, 2, \dots, 5 \)): Coefficients for the Auto-Regressive (AR) terms (from lag 1 to lag 5).</li>
    <li>\( Y_{t-i} \): The value of the time series at previous time steps (\( t-1, t-2, \dots, t-5 \)).</li>
    <li>\( \theta_i \) (\( i = 1, 2, \dots, 5 \)): Coefficients for the Moving Average (MA) terms (past errors).</li>
    <li>\( \epsilon_{t-i} \): Errors at previous time steps (\( t-1, t-2, \dots, t-5 \)).</li>
    <li>\( \epsilon_t \): Error term at time \( t \).</li>
    </ul>
    
<h4>Process</h4>
<p>The process of applying my ARIMA model involved several key steps. It is especially important to note that the results were specified down to the Florida, USA level due to the mass size of the data.:</p>

<ol>
  <li>I processed the data from the Johns Hopkins dataset. They had the data already prepared and cleaned, organized by the country, province, state, update, confirmed cases, and more variables. These are the ones I focused on.</li>
  <li>I made sure that the date and time variables were all formatted correctly and cleaned up any NaN values.</li>
  <li>I graphed the general USA COVID-19 graph to see the structure in which the data was moving and determined it was not stationary because it had both a positive trend and it seemed to be affected by some sort of seasonality (this will be explored more in the SARIMA model).</li>
  <li>To determine if the model was stationary or not stationary, I also employed the ADF test, which follows: </li>
    <ul>
    <li><strong>H0:</strong> The data is non-stationary.</li>
    <li><strong>H1:</strong> The data is stationary.</li>
</ul>
  <li> Due to the fact that my p-value was greater than 0.05, we fail to reject the null hypothesis, and therefore perform a first order differencing on the model. Which is then seen to be stationary under this hypothesis.<li>
  <li>Using the AIC function, I determined the most ideal ARIMA model parameters for (p,d,q).</li>
  <li>I fitted the model and checked the residuals for white noise.</li>
  <li>Developed a forecast for the next 30 days for the state of Florida.</li>
</ol>
      <h2>SARIMA Model with Weekly Seasonality</h2>
    
    <p>After performing the ARIMA model, it can be seen that the data would have been better fitted with a SARIMA model. SARIMA, an extention of ARIMA, also works with linear regression however takes into consideration of the complexity that seasonality can hold within our data. As it can be seen in the EDA, the data has a cylcial pattern. This is common within different epidemiolgy such as flu season, where there are times the data spikes and decreases as medical advances (in our case COVID-19 vaccines or leaving the winter season) can cause diagnosis of COVID-19 to increase or decrease.</p>
    <p>Within the code we explored, the seasonal part of the SARIMA model would look like:</p>
    <pre><code>
    C_t = ϕ_1 C_{t-1} + θ_1 ε_{t-1} + Φ_1 C_{t-7} + Θ_1 ε_{t-7}
    </code></pre>
        <li><b>C_t</b>: The value of the confirmed cases at time <i>t</i>.</li>
        <li><b>ϕ_1</b>: Non-seasonal autoregressive (AR) term, which represents the influence of the immediate past value <code>C_{t-1}</code> on the current value.</li>
        <li><b>θ_1</b>: Non-seasonal moving average (MA) term, which represents the influence of the previous error <code>ε_{t-1}</code> on the current value.</li>
        <li><b>Φ_1</b>: Seasonal autoregressive (SAR) term, which represents the influence of the past value one season ago (in this case, <code>C_{t-7}</code>) on the current value, capturing weekly patterns.</li>
        <li><b>Θ_1</b>: Seasonal moving average (SMA) term, which represents the influence of the error from one season ago (in this case, <code>ε_{t-7}</code>) on the current value, also capturing weekly patterns.</li>
        <li><b>ε_t</b>: Error term at time <i>t</i>.</li>
    </ul>
</body>
</html>

  <h3>Bayesian Structural Time Series Model (BSTS)</h3>
<p>The BSTS model can be represented as follows:</p>
<p>
\[Y_t = T_t + S_t + X_t \beta + \epsilon_t\]
</p>
<p>Where:</p>
<ul>
  <li>\( Y_t \) is the observed value of the time series at time \( t \) (e.g., COVID-19 confirmed cases in Florida).</li>
  <li>\( T_t \) represents the trend component, which captures the overall movement of the COVID-19 cases over time.</li>
  <li>\( S_t \) is the seasonal component, used to model recurring weekly in my COVID-19 data.</li>
  <li>\( X_t \) represents the regressors, which include external variables such as public policies, mobility, or vaccination rates.</li>
  <li>\( \beta \) is the vector of regression coefficients for the regressors.</li>
  <li>\( \epsilon_t \) is the error term at time \( t \), accounting for random noise.</li>
</ul>

<p>For the COVID-19 data in Florida, the BSTS model captures the underlying trend, any seasonal effects (such as pandemic waves or reporting delays), and the effect of external factors like public health measures. Bayesian estimation allows for uncertainty quantification, and the components are estimated using Markov Chain Monte Carlo (MCMC) methods to fit the model.</p>

<h4>Process ( This is GENERAL right now, WILL make more specific as I code) </h4>
<ol>
  <li>Load the dataset and ensure all necessary variables are in the appropriate format for time series analysis (e.g., convert dates to datetime format, handle missing values).</li>
  <li>Define the components of the BSTS model, such as the trend, seasonal, and regression components. Each component captures a specific feature of the time series, like long-term patterns or periodicity.</li>
  <li>Use a Bayesian approach to estimate the model parameters based on the observed data. This involves setting priors and using Markov Chain Monte Carlo (MCMC) methods to fit the model.</li>
  <li>Assess model fit by evaluating posterior distributions of parameters, inspecting residuals, and computing prediction intervals to ensure the model is capturing the underlying patterns of the data.</li>
  <li>Use the fitted BSTS model to generate future forecasts. Predictive intervals are also computed, allowing for uncertainty quantification in the forecasts.</li>
  <li>Perform model diagnostics such as comparing predictions to actual values (cross-validation) or calculating prediction accuracy metrics like Mean Absolute Error (MAE) to validate the model's performance.</li>
  <li>Plot the time series, model components, and forecasted values to visually evaluate how well the model explains the data.</li>
</ol>
    
 <h2>Methods for CO2 Emission Forecasting</h2>
 <h2>Data Cleaning</h2>

<p>Upon downloading the file directly from the website, several adjustments were necessary:</p>

<ol>
    <li>The dataset included a descriptive section at the top, detailing information about public use, data stewardship, and other general information. In the CSV file, this was misinterpreted as part of the data, resulting in a lack of proper column headers. This section needed to be deleted to correctly read the dataset.</li>
    <li>The dataset documentation also mentioned that some missing days are asymmetric, which could introduce a high or low bias in the monthly averages. This required attention when handling missing data.</li>
    <li>Due to the eruption of the Mauna Loa volcano, data collection at the Mauna Loa Observatory was suspended from November 29, 2022, and resumed in July 2023. This gap in the data needed to be addressed during analysis.</li>
    <li>The original dataset did not explicitly include "Year" and "Month" columns; however, they were implied by the "decimal.date" field. To facilitate analysis, these headings were added based on the decimal date values.</li>
</ol>

<h2>Methods for CO2 Emission Forecasting</h2>

<h3>ARIMA Method:</h3>

<p>To forecast CO2 emissions, we first download the dataset from the NOAA Global Monitoring Laboratory website, where they monitor monthly CO2 emissions at Mauna Loa. After downloading the dataset, I loaded it into a Jupyter Notebook for graphing and exploration.</p>
<p>Initially, the graph of the CO2 data showed both a seasonal pattern and an upward trend, suggesting that the data is non-stationary. To confirm this, I applied the Augmented Dickey-Fuller (ADF) test, which tests the following hypotheses:</p>

<ul>
    <li><strong>H0:</strong> The data is non-stationary.</li>
    <li><strong>H1:</strong> The data is stationary.</li>
</ul>

<p>Using a significance level of 0.05, if the p-value is less than 0.05, we reject the null hypothesis. In this case, the p-value from the ADF test was 1, which is greater than 0.05. This indicates that the data is non-stationary, and stationarization is required.</p>
<p>To address this, I applied the differencing technique. After differencing the data, I re-applied the ADF test, which resulted in a p-value of 0.00005, indicating the data is now stationary.</p>
<p>Next, I examined the Partial Autocorrelation Function (PACF) and Autocorrelation Function (ACF) plots derived from the differenced data. Based on these plots, two potential ARIMA models were identified: (3,1,2) and (3,1,1). I used Python's Statsmodels library to fit these models and selected the model with the lowest Akaike Information Criterion (AIC) value, which turned out to be the (3,1,2) model. This model was then used to forecast CO2 emissions up to 2025. While the forecast captured the general upward trend, it did not adequately represent the seasonality in the data.</p>

<h3>SARIMA Model:</h3>
<p>To address the seasonality, I applied a Seasonal ARIMA (SARIMA) model. Using the same non-seasonal order (3,1,2), I added a seasonal order of (1,1,12) to account for the monthly seasonality. After fitting the SARIMA model and forecasting 60 steps ahead, the resulting forecast captured both the trend and the seasonality of the data, providing a more accurate projection.</p>

</div>    
<!-- Tab content for References -->
<div id="References" class="tabcontent">
  <h2>References</h2>
  <ul>
    <li><strong>[1] Kulshreshtha, Vikas, and N. K. Garg. 2020.</strong> "Predicting the New Cases of Coronavirus [COVID-19] in India by Using Time Series Analysis as Machine Learning Model in Python." <em>The Institution of Engineers (India)</em>.</li>
    <li><strong>[2] Demongeot J, Oshinubi K, Rachdi M, et al. 2021.</strong> "The Application of ARIMA Model to Analyze COVID-19 Incidence Pattern in Several Countries." <em>Journal of Mathematics and Computer Science</em>.</li>
    <li><strong>[3] Wang, Yanding, et al. 2022.</strong> "Prediction and Analysis of COVID-19 Daily New Cases and Cumulative Cases: Time Series Forecasting and Machine Learning Models." <em>BMC Infectious Diseases</em>, vol. 22, p. 495.</li>
    <li><strong>[4] Fotia, Pasquale, and Massimiliano Ferrara. 2023.</strong> "A Different Approach for Causal Impact Analysis on Python with Bayesian Structural Time-Series and Bidirectional LSTM Models." <em>Atti della Accademia Peloritana dei Pericolanti</em>.</li>
    <li><strong>[5] Nielsen, Michael. 2015.</strong> <em>Neural Networks and Deep Learning</em>. Determination Press.</li>
    <li><strong>[6] Ning, Yanrui, Hossein Kazemi, and Pejman Tahmasebi. 2022.</strong> "A Comparative Machine Learning Study for Time Series Oil Production Forecasting: ARIMA, LSTM, and Prophet." <em>Computers & Geosciences</em>, vol. 164, 105126.</li>
    <li><strong>[7] Tinungki, G.M. 2019.</strong> "The Analysis of Partial Autocorrelation Function in Predicting Maximum Wind Speed." <em>IOP Conference Series: Earth and Environmental Science</em>, vol. 235, 012097. <a href="https://doi.org/10.1088/1755-1315/235/1/012097">https://doi.org/10.1088/1755-1315/235/1/012097</a>.</li>
    <li><strong>[8] Psychology Learning & Teaching, 2020.</strong> "The Importance of Cross-Validation in Time Series Forecasting and Bayesian Inference." <em>Psychology Learning & Teaching</em>, vol. 19(1), 21–35. <a href="https://doi.org/10.1177/1475725719874542">https://doi.org/10.1177/1475725719874542</a>.</li>
  </ul>
</div>


   <!-- JavaScript to handle tab switching -->
  <script>
    function openTab(evt, tabName) {
      var i, tabcontent, tablinks;
      tabcontent = document.getElementsByClassName("tabcontent");
      for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
      }
      tablinks = document.getElementsByClassName("tablinks");
      for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
      }
      document.getElementById(tabName).style.display = "block";
      evt.currentTarget.className += " active";
    }

    // Open the default tab
    document.getElementById("defaultOpen").click();

    // Force MathJax to render any LaTeX
    MathJax.typeset();
  </script>

</body>
</html>
