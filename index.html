<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Time Series Project</title>
  <style>
    /* Simple tab styles */
    .tab {
      overflow: hidden;
      background-color: #f1f1f1;
    }

    .tab button {
      background-color: inherit;
      border: none;
      outline: none;
      cursor: pointer;
      padding: 14px 16px;
      transition: 0.3s;
      font-size: 17px;
    }

    .tab button:hover {
      background-color: #ddd;
    }

    .tab button.active {
      background-color: #ccc;
    }

    .tabcontent {
      display: none;
      padding: 6px 12px;
      border-top: none;
    }

    .tabcontent.active {
      display: block;
    }
  </style>
    <!-- Include MathJax for LaTeX rendering -->
  <script type="text/javascript" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  
</head>
<body>

  <h1>Explorations of Time Series Analysis Techniques and Forecasting Methods on Real-World Applications</h1>

  <!-- Tab buttons -->
  <div class="tab">
    <button class="tablinks" onclick="openTab(event, 'LitReview')" id="defaultOpen">Literature Reviews</button>
    <button class="tablinks" onclick="openTab(event, 'Intro')">Introduction</button>
    <button class="tablinks" onclick="openTab(event, 'Methods')">Methods</button>
    <button class="tablinks" onclick="openTab(event, 'Results')">Results</button>
    <button class="tablinks" onclick="openTab(event, 'Presentation')">Presentation</button>
    <button class="tablinks" onclick="openTab(event, 'References')">References</button>
  </div>

  <!-- Tab content for Literature Reviews -->
  <div id="LitReview" class="tabcontent">
    <h2>Literature Reviews</h2>
    <p>My semester project focuses on exploring time series analysis using ARIMA/SARIMA and Bayesian models to forecast and analyze the spread of COVID-19 and CO₂ emissions in Mauna Loa, Hawaii. Below are the literature reviews I have completed, highlighting the methods and techniques applied in my research.</p>
    <ul>
      <li><a href="Capstone_Paper_Review_Literature_Review__Week1.pdf">Week 1 Review</a></li>
      <li><a href="https://github.com/GianyceG/gianyceg.github.io/blob/main/Capstone_Paper_Review_Literature_Review__2_%20(1).pdf">Week 2 Review</a></li>
      <li><a href="https://github.com/GianyceG/gianyceg.github.io/blob/main/Capstone_Paper_Review_Literature_Review__3_%20(1).pdf">Week 2 Paper 2 Review</a></li>
      <li><a href="https://github.com/GianyceG/gianyceg.github.io/blob/main/Capstone_Paper_Review_Literature_Review__4_%20(1).pdf">Week 3 Review</a></li>
    </ul>
  </div>

<!-- Tab content for Introduction -->
  <div id="Intro" class="tabcontent">
<img src="images/Screenshot%202024-10-14%20212930.png" alt="Time Series Forecast" width="600" height="300">
<p><em>Source: <a href="https://towardsdatascience.com/an-introduction-to-time-series-analysis-with-arima-a8b9c9a961fb" target="_blank">An Introduction to Time Series Analysis with ARIMA, Towards Data Science</a></em></p>
    <h2>Abstract</h2>
    <p>This study explores time series forecasting techniques using ARIMA, SARIMA, and Bayesian models on two distinct datasets: the COVID-19 dataset from the Johns Hopkins CSSEGISandData repository and the CO₂ emissions data from Mauna Loa, Hawaii, provided by NOAA. The primary goal is to clean the datasets and implement forecasting models to assess their strengths and limitations. For large datasets, such as COVID-19, both ARIMA and SARIMA models demonstrated rapid processing capabilities but exhibited high variability. Both models produced nearly identical forecasts, which suggests potential overfitting or redundancy. Further investigation is required to fully explore the performance of the Bayesian model on this dataset. In contrast, the smaller Mauna Loa CO₂ dataset, which exhibits smoother seasonal patterns, allowed for more accurate forecasting. Among the tested models, the Bayesian model provided the most precise predictions, with a Root Mean Square Error (RMSE) of 0.765 and a Mean Absolute Percentage Error (MAPE) of 0.16%. The ARIMA and SARIMA models performed adequately, but their RMSE values were higher: 12.55 and 13.38, respectively. This analysis highlights the Bayesian model in handling stable and seasonally predictable datasets, while ARIMA-based models may struggle when applied to complex and volatile data, such as the COVID-19 dataset. These results demonstrate the importance of model selection based on the nature and structure of the dataset for effective forecasting.</p>
    <h2>Introduction</h2>
    <p>Anything that is observed sequentially over time is a time series. In the data, I will look at regular intervals of time. Time series forecasting is a statistical method used to predict future values based on past results. The simplest models focus solely on the variable being forecast, ignoring external factors like marketing efforts or economic shifts, and instead extrapolating existing trends and seasonality. Specifically in this capstone, I will be exploring univariate models ARIMA/SARIMA and the Bayesian STS.</p>
    <p>The use of time series analysis gained recognition since 1970 when the Box-Jenkins method popularized ARIMA models to find the best fit of different time series models based on past data. However, the concept of analyzing sequential data over time is not new. As the world increasingly embraces data-driven solutions to forecast future industry outcomes, time series analysis has become vital in numerous fields. </p>
<p>Currently, efforts to perfect the science of forecasting is important as the higher the accuracy of a time series based on past data and events, the more essential the tool becomes for modern organizations as accurate forecasts support decision-making across various timeframes—whether short-term, medium-term, or long-term, depending on the specific application. Key considerations in forecasting include seasonality, trends, and external fluctuations, which play a significant role in shaping predictions. These specifically will be explored more as I deal with the data sets of this project. These forecasts are integral for planning, resource allocation, and adjusting strategies in response to upcoming movements.</p>
  <p>The main goal of my paper is to explore and discuss the concept and use real life datasets in order to see how time series analysis can use its historical data and leverage practical and meaningful conclusions. In this paper, we will also be discussing any possible limitations that the different time series models have and what some suggestions are to improve our predictions and possibly overcome these limitations. <p>
    <p>In this capstone, I will explore the Johns Hopkins CSSEGISandData COVID-19 Repository, which tracks global COVID-19 cases and Our World in Data (OWID), which provides comprehensive COVID-19 datasets across various indicators datasets to test the univariate models ARIMA/SARIMA and Bayesian STS. Using the same model structures, I will also be exploring the Forecasting CO₂ Emissions in Mauna Loa, Hawaii. This dataset is provided by the Global Monitoring Laboratory within NOAA. The goal of this exploration is to apply time series analysis to forecast the future spread of COVID-19, seeing which models are the strongest to do such a task, and to use those same models to appropriately forecast the increasing trend of the CO₂ emission rates. These two different datasets and applications are to show the strength in forecasting in multiple real-life situations. This is important in data science and statistics, particularly in public health and global policy as creating accurate forecasts can allow policymakers a better direction on what should be applied and when. </p>
    <p>To achieve the goals of my capstone, ARIMA/SARIMA will be used for capturing linear trends and seasonal effects, and Bayesian STS for incorporating uncertainty and providing probabilistic forecasts. The project will begin with an exploratory data analysis (EDA) to visualize the time series data, identify patterns, and check for seasonality or trends. After cleaning and preprocessing the data, I will test both models using Python on the COVID-19 and CO₂ datasets. The results will then be compared to assess which approach yields the most accurate and insightful forecasts. </p>
<h2>Time Series Forecasting Models</h2>
  <p>In different papers and studies, it is easy to see that there are a multitude of models to explore and chose from, depending on what is being questioned or asked from by the researcher and data. Most of the models can be seen following into different categories. Traditional statistical modeling, which includes a moving average, exponential smoothing, and autoregressive (ARIMA). These are seen as linear functions taking past observations to make sound predictions. Second category of model type is nonlinear models. This will not be covered in my project, but the main difference lies in the complexity and non-proportional relationships in the data. An example of this can be LSTM, ANN, NAR models. The second main model type that I will be covering is the Bayesian Structural Time Series (BSTS). This model type is considered linear, since it relies on the state-space models, but can handle much more complexity such as trend, seasonality, and regression components. So, although it is linear, the approach is more flexible by adding prior distributions allowing for uncertainty estimations. In this capstone, these two ARIMA/SARIMA and Bayesian STS will be explore in depth.  </p>
   
<h3>ARIMA Model</h3>
<p>To begin, throughout this project I will be utilizing the ARIMA model as a traditional method of time series forecasting. ARIMA stands for Autoregressive integrated moving average and it predicts future values with past values. It utilizes lagged moving averages to smooth the time series data. The ARIMA model is a univariate model that can be broken down into two different models, AR and MA, which will be define below.</p>
<p>The ARIMA model is defined by the parameters \( (p, d, q) \), where:</p>
<ul>
  <li>\( p\) is the number of lag observations (autoregressive terms).</li>
  <li>\( d\) is the number of times the data must be differenced to make it stationary.</li>
  <li>\( q\) is the number of lagged forecast errors (moving average terms) <a href="#ref1">[1]</a>.</li>
</ul>

<p>The ARIMA model is composed of two submodels, the AR (Autoregressive) and the MA (Moving Average) model, described mathematically as follows:</p>
<p>\[Y(AR)_t = \alpha + \beta_1 Y(AR)_{t-1} + \beta_2 Y(AR)_{t-2} + \cdots + \beta_p Y(AR)_{t-p}\] (1)</p>
<p>where \( Y(AR)_t \) are the lags of the series, \( \beta \) are the lag coefficients estimated by the model, and \( \alpha \) is the model’s intercept term.</p>
<p>\[Y(MA)_t = \epsilon_t + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \cdots + \theta_q \epsilon_{t-q}\] (2)</p>
<p>where \( Y(MA)_t \) depends only on the lagged forecast errors, \( \theta \) are the parameters of the model, and \( \epsilon \) are unrelated error terms.</p>
<p>The mathematical expression of the ARIMA model, as a combination of AR and MA models, is:</p>
<p>\[Y_t = \alpha + \sum_{i=1}^{p} \beta_i Y_{t-i} + \epsilon_t - \sum_{j=1}^{q} \theta_j \epsilon_{t-j}\] (3)</p>
<p>Where \( Y_t \) and \( \epsilon_t \) represent the time series and the random error at time \( t \), \( \beta \) and \( \theta \) are the coefficients of the model.</p>
<p>When estimating the \( p\) and \( q\) parameters of the AR and the MA models, plots from the ACF function and the PACF functions are used. Just to summarize, the autocorrelation function, ACF, is a function that shows the correlation between the observed of the \(t \) time and the observation at the previous times. This function indicates the autocorrelation coefficient, which is the measurement of the correlation between observations at different times. PACF, or partial autocorrelation function differs because it is the correlation between two random variables after the influence of confounding variable is removed <a href="https://iopscience.iop.org/article/10.1088/1755-1315/235/1/012097/pdf" target="_blank">[7]</a>.</p>

<img src="images/Screenshot 2024-10-15 004734.png" alt="Stationary_Example" width="600" height="300">
<p><em>Source: <a href="https://www.researchgate.net/publication/348592737/figure/fig3/AS:981645804970018@1611054006754/Examples-for-stationary-and-non-stationary-time-series.png" target="_blank">Classification of Time Series</a></em></p>

<p>Prior to finding the ACF/PACF, it is obligated for us to know if the data that is obtained is stationary or nonstationary. This is important because if the data is not stationary, the data cannot perform the ARIMA model accurately. Therefore, in order to determine if the model is stationary, it can be visualized or the Dickey-Fuller Test can be performed to determine the classification of the time series data.</p>
<p>When differencing is applied and observed, the \(p\) order deals with the AR model and it is based on the significant spikes from the PACF plot. The MA model, \(q\) order is determined if the ACF plots have sharp cut-off after lags. If there has been any differencing applied to the model, \(d\) is determined by the order of the differencing (i.e. how many times the differencing has been applied).   </p>
<p>After the strongest combination of the \( (p, d, q) \) have been selected, it is possible to then run the ARIMA model and see the results. At times, it can be difficult to physically pick out the correct combination. If this becomes the case, there are machine learning approaches to choose the appropriate orders.</p>

<h2>Bayesian Structural Time Series Model</h2>

<p> Fundamentally, this theorem is unique from ARIMA due to differences in the interpretation of what “probability” means. We will explore criticisms later, but it is important to remember this distinction when understanding the model differences. Bayesian inference is a method of statistical inference where available knowledge about parameters in a statistical model is updated with information from observed data. 
  <a href="https://www.nature.com/articles/s43586-020-00001-2" target="_blank">A Guide to Bayesian Inference</a>. </p>
<p>Bayesian inference provides a powerful framework to update beliefs as new data becomes available. It allows us to calculate the probability of an event occurring, given prior knowledge and new evidence. A simplified version of Bayes’ theorem looks like this:</p>

<img src="images/Screenshot 2024-10-20 011921.png" alt="Bayes' Theorem Visualization" width="500" height="250">
<p><em> <a href="https://sreedattavajinapally.medium.com/bayesian-time-series-forecasting-89c8ec4a1dde" target="_blank">Bayesian Time Series Forecasting</a></em></p>


<p>Referring to the image explaining the visualization, it breaks down the components as follows:</p>
<ul>
  <li><strong>Prior (P(A))</strong>: The initial belief about the probability of event A, before new evidence is considered.</li>
  <li><strong>Likelihood (P(B | A))</strong>: The probability of observing evidence B given that event A has occurred.</li>
  <li><strong>Marginal (P(B))</strong>: The total probability of observing the evidence across all possible events.</li>
  <li><strong>Posterior (P(A | B))</strong>: The updated belief about event A given the new evidence B.</li>
</ul>
<p>This framework is fundamental in Bayesian time series analysis, allowing models to  update predictions as new data arrives. The posterior distribution represents the estimation of a parameter, ensuring the model reflects both the past trends and the latest observations.</p>

<p><em>Source: Created based on Bayes' theorem principles, adapted for better interpretability.</em></p>

<p> Now, for Bayesian Structural Time-Series Models, the time series can be broken down into four basic models depending on the following: a level, a local trend, seasonal impacts, and an error term. Structural Time Series models can be defined by the following:</p>
<div class="equation">
  <div> \[ y_t = Z_t^T \alpha_t + \varepsilon_t \] </div>
  <div class="equation-number">(4)</div>
</div>

<div class="equation">
  <div> \[ \alpha_{t+1} = T_t \alpha_t + R_t \eta_t \] </div>
  <div class="equation-number">(5)</div>
</div>

<p> Equation (4) and Equation (5) represent the structure of the model. Equation (4) is trying to understand the 
  distribution of the \( Y_t \)’s of the data, while Equation (5) is closely related to understanding the distribution 
  of the parameters. It provides the evolution model for the parameters and how they change over time. 
  Because the vector evolves through randomness, it describes the distribution of the hidden parameters at the next step. 
  This is crucial because for Bayesian inference to hold, updating the beliefs of the parameters helps incorporate 
  both the priors and the observed data.</p>

<h2>Criticism and Limitations</h2>
  <p> The key distinction between the ARIMA and Bayesian methods lies in their underlying theoretical perspectives: frequentist vs. Bayesian. In the frequentist approach (as used in ARIMA models), parameters are treated as fixed values that do not change once estimated. The data is analyzed under the assumption that these parameters have unique, fixed points. </p>
  <p> In contrast, the Bayesian approach views parameters as random variables that can evolve over time, with uncertainty captured through prior distributions. This flexibility allows the Bayesian method to incorporate prior knowledge about the parameter’s movement and update these beliefs as new data becomes available, resulting in what is known as posterior distributions. </p>
  <p> This difference introduces a potential limitation: if the prior distribution is inaccurate or misinformed, it can negatively affect the model’s output. While prior information can enhance predictions, it can also become a burden if the assumptions are flawed or if prior knowledge conflicts with new observations. Therefore, Bayesian models offer both advantages and risks: they excel when reliable prior knowledge is available but can be inaccurate if the priors introduce bias into the model. </p>
  <p> Next, time series analysis inherently faces criticism because it attempts to predict the future—data that has not yet materialized—with as much certainty as possible. When practicing time series forecasting, it is crucial to not only critique the model’s inference but also incorporate evaluation methods into the decision-making process, given the inherent uncertainty of projections. </p>
  <p> While cross-validation techniques are still applicable and recommended for time series models, specific approaches such as leave-one-out (LOO) cross-validation can pose challenges. For time series, LOO can be problematic when the goal is to estimate predictive performance for future time points, as removing an observation disrupts the temporal dependencies in the data. This is particularly problematic from a Bayesian perspective, where each time point informs the next. Ignoring these dependencies undermines the theoretical foundation of time series models, which rely on the structure of sequential observations. </p>

</div>
  
<!-- Tab content for Methods for COVID-19 -->
  <div id="Methods" class="tabcontent">
    <h2>Methods </h2>
    <p>My project explores time series forecasting using two distinct datasets: one focused on COVID-19 case trends and the other on the NOAA Mauna Loa CO₂ emission dataset. I will apply my forecasting models to both datasets and evaluate their predictive performance. The models’ strengths will be compared across the two datasets to assess their ability to capture different patterns and trends. Finally, I will generate a summary detailing the strengths, weaknesses, and limitations encountered throughout the project.</p>    
<h3>Johns Hopkins COVID-19 Exploration </h3>
<p>This part of the project uses time series forecasting on the COVID-19 dataset from the Johns Hopkins CSSEGISandData, with an emphasis on modeling the data using ARIMA/SARIMA and Bayesian Structural Time Series (BSTS). Both are univariate (single-variable) time series methods without trend or seasonal components, while other time series models, such as SARIMA, can capture multivariate series with trends and seasonal patterns. Within this capstone, I will demonstrate how the predictions appear when forecasted using ARIMA, SARIMA, and BSTS. Then, I will compare the results, determine which model is best suited for the COVID-19 dataset, and revisit the limitations of the models based on the outcomes of their applications.</p>
  <p> First, the data will be loaded into JupyterNotebook and processed with Python. Then, the data is already cleaned through the github repository CSSEGISandData.  <p>
    <p>Using Python, the key libraries utilized for processing my ARIMA model were Pandas, Matplotlib, and Statsmodels. I used Pandas extensively for data manipulation, including loading the dataset, converting date columns to datetime format, applying differencing to achieve stationarity, and other data preparation tasks. Matplotlib was instrumental in visualizing the time series, including plotting the original and differenced data, as well as visualizing the autocorrelation and forecast results. Statsmodelswas used to fit the ARIMA model and provided essential tools for analyzing time series properties, such as plotting the partial autocorrelation function (PACF) and autocorrelation function (ACF), as well as fitting the model itself to make predictions.</p>
<p>To begin the data exploration, I processed the data from the Johns Hopkins dataset. The dataset was already prepared, cleaned, and organized by country, province, state, date, confirmed cases, and more. After loading the dataset into Jupyter Notebook, I examined its structure and content. To explore the dataset further, I applied a rolling statistic. This approach visualizes a moving window along the time series, which is particularly useful with ARIMA as it helps to observe moving averages. These rolling averages smooth out short-term fluctuations, providing a clearer view of the underlying trends in the data.</p>
   <h3>ARIMA and SARIMA Forecasts</h3>
    <img src="images/Screenshot 2024-10-15 064846.png" alt="Rolling_Mean_STD" width="600" height="300">
    <pre><code> 
rolling_mean_us = us_data['Confirmed'].rolling(window=30).mean()
rolling_std_us = us_data['Confirmed'].rolling(window=30).std()

plt.figure(figsize=(12, 6))
plt.plot(us_data['Confirmed'], color='b', label='Original Confirmed Cases', linewidth=1)
plt.plot(rolling_mean_us, color='r', label='Rolling Mean (30 days)', linewidth=1.5)
plt.fill_between(us_data.index, rolling_mean_us - rolling_std_us, rolling_mean_us + rolling_std_us, color='gray', alpha=0.3, label='Rolling Std Dev (30 days)')
plt.title('Rolling Mean & Standard Deviation of COVID-19 Confirmed Cases in the US (2020 - 2023)')
plt.xlabel('Date')
plt.ylabel('Confirmed Cases')
plt.legend(loc='best')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
</code></pre>

    <p><em>Rolling Mean and Rolling Standard Deviation over 7-day periods, showing the trend of confirmed COVID-19 cases in Florida (2020-2023).</em></p>
    <p>After creating a line graph displaying the trend of confirmed COVID-19 cases over time, it became clear that the sheer volume of data required narrowing the focus. I chose to concentrate on Florida, my home state. The data exhibited seasonality, with confirmed cases rising as the weeks progressed. I began by processing the Johns Hopkins dataset, which was already organized by country, state, and confirmed cases, among other variables. I ensured all date and time variables were correctly formatted, addressing any missing values along the way. I plotted a general USA COVID-19 graph to analyze the structure, which revealed a positive trend and signs of seasonality.</p>
    <p>First, to point out the code, the cleaned data set allows me to calculate the means with ease. I used a window of 30 days for both the means and standard deviation. Then, as it can be seen, the blue line of confirmed cases, or the cumulative data has small rigidness on the line. When the rolling mean was applied, it smoothed out the curve based on the 7-day rolling window. This averages out the daily changes to the data over a week at a time. Because the changes of the window size is low, the standard deviation line in green will appear low, indicating that the variations over that period are not significant. All this is applicable to our data as the nature of COVID-19’s spread tends to increase in a consistent matter over time, except as we can see in 2022-01, we had a significant spike. Aside from that, the rolling standard deviation proves that there is lower variability. </p>
    <p>As I am exploring and graphing the data, I made sure that the date and time variables were all formatted correctly and cleaned up any NaN values. Then, I begin the ARIMA process. Visually, the data appears to be stationary. This can be determined by the characteristics that it is trending upwards and has some sort of seasonality since there is a pattern with in the upward trend that appears to be relatively consistent. However, if I want to make sure I will approach by applying the Dickey-Fuller hypothesis testing. </p>
<ul>
    <li><strong>H0:</strong> The data is non-stationary.</li>
    <li><strong>H1:</strong> The data is stationary.</li>
</ul>
  <pre><code>
print('Results of Dickey-Fuller Test:')
dftest = adfuller(us_data['Confirmed'], autolag='AIC')
dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '# Lags Used', 'Number of Observations Used'])
for key, value in dftest[4].items():
dfoutput['Critical Value (%s)' % key] = value
print(dfoutput)
  </code></pre>
  <p>This code allows us to test the ADF hypothesis. The outcome of this was that my p-value was greater than 0.05, so we fail to reject the null hypothesis, and therefore perform a first order differencing on the model.</p> 

<pre><code>
fl_data = cleaned_data[(cleaned_data['Country_Region'] == 'US') & (cleaned_data['Province_State'] == 'Florida')].copy()
fl_data['Last_Update'] = pd.to_datetime(fl_data['Last_Update'], errors='coerce')
fl_data = fl_data.dropna(subset=['Last_Update', 'Confirmed'])
fl_data['Confirmed'] = pd.to_numeric(fl_data['Confirmed'], errors='coerce')
fl_data = fl_data.groupby('Last_Update')['Confirmed'].sum().reset_index()
fl_data = fl_data.sort_values('Last_Update')
fl_data.set_index('Last_Update', inplace=True)
fl_data['Differenced_Confirmed'] = fl_data['Confirmed'].diff()
fl_data.dropna(subset=['Differenced_Confirmed'], inplace=True)
</code></pre>
    
<p>So, I specifically am attempting to stationarize the Florida COVID data, which is seen with the Country Region and State being Florida. Then, after doing data cleaning to structure the data in preparation of stationarization, I apply the differencing to the data. Which is then seen to be stationary under this hypothesis. Since this has now confirmed that the data is stationary, a first order differencing is now necessary to continue.</p>
<p>After the data is differenced, I performed the ADF again, and this time the p-value was less than 0.05. Therefore, the process can continue.</p>
<img src="images/Screenshot 2024-10-30 053139.png " alt="Differenced COVID-19 Data" width="600" height="300">
<p>Now, from here it is possible to choose an ideal model from the PACF/ACF models, but I used the ARIMA Order Select AIC function that is found in the statsmodels.tsa.stattools package. The reason I decided to do this instead of looking at the PACF/ACF was because of the variability within those graphs, I believe that using this tools lets me be more efficient and also more accurate since if I chose I could have human error. </p>
<pre><code>
from statsmodels.tsa.stattools import arma_order_select_ic
order_selection = arma_order_select_ic(fl_data['Differenced_Confirmed'].dropna(), ic='aic', max_ar=5, max_ma=5)
print(order_selection.aic_min_order)
</code></pre>
<p> From this code, I achieved the following ARIMA order = (5,0,5). Then, I used this to fit my ARIMA model. </p>
<pre><code>
model = ARIMA(fl_data['Differenced_Confirmed'].dropna(), order=(5, 0, 5))
fit_arima = model.fit()
print(fit_arima.summary())
</code></pre>
<img src="images/Screenshot 2024-10-30 053234.png " alt="COVID-19 ARIMA Forecast" width="600" height="300">
    
<p>Developed SARIMA Model:</p>
    <p>For this COVID-19 dataset, the SARIMA model extends ARIMA by incorporating seasonality. The mathematical expression of my SARIMA model is:</p>
    <p>After performing the ARIMA model, it can be seen that the data would have been better fitted with a SARIMA model. SARIMA, an extention of ARIMA, also works with linear regression however takes into consideration of the complexity that seasonality can hold within our data. As it can be seen in the EDA, the data has a cylcial pattern. This is common within different epidemiolgy such as flu season, where there are times the data spikes and decreases as medical advances (in our case COVID-19 vaccines or leaving the winter season) can cause diagnosis of COVID-19 to increase or decrease.</p>
    <p>Within the code we explored, the seasonal part of the SARIMA model would look like:</p>
   
    <p>\[ Y_t = c + \phi_1 Y_{t-1} + \dots + \phi_p Y_{t-p} + \theta_1 \epsilon_{t-1} + \dots + \theta_q \epsilon_{t-q} + \Phi_1 Y_{t-s} + \Theta_1 \epsilon_{t-s} + \epsilon_t \] </p>
    <p>Where:</p>
<ul>
    <li>\( Y_t \): The value of confirmed cases at time \( t \).</li>
    <li>\( c \): Constant term (intercept).</li>
    <li>\( \phi_i \) (\( i = 1, 2, \dots, p \)): Coefficients for the non-seasonal AR terms.</li>
    <li>\( \theta_i \) (\( i = 1, 2, \dots, q \)): Coefficients for the non-seasonal MA terms.</li>
    <li>\( \Phi_1 \): Seasonal AR term, representing the influence from one seasonal lag (e.g., \( Y_{t-s} \)).</li>
    <li>\( \Theta_1 \): Seasonal MA term, representing the effect of an error from one seasonal lag (\( \epsilon_{t-s} \)).</li>
    <li>\( s \): Seasonal period (e.g., weekly seasonality with \( s = 7 \)).</li>
    <li>\( \epsilon_t \): Error term at time \( t \).</li>
</ul>
    <p>Now, the main difference between the ARIMA and the SARIMA is the addition of the \( s \) term. When I was exploring the data, it was seen that the data had an upward trend throughout the whole set, but also the data temporally increased every 7 days. Therefore, I chose to have a weekly seasonality within the dataset. The comparison between these two models can be seen in the results tab. </p>
    <p>The developed SARIMA model's code still stems from ARIMA, but the difference is the addition of the seasonality.</p>
    <pre><code>
from statsmodels.tsa.statespace.sarimax import SARIMAX
sarima_model = SARIMAX(fl_data['Differenced_Confirmed'].dropna(), 
                       order=(5, 0, 5), 
                       seasonal_order=(1, 1, 1, 7))

fit_sarima = sarima_model.fit()
forecast_steps = 60
forecast = fit_sarima.forecast(steps=forecast_steps)
    </code></pre>
    <img src="images/Screenshot 2024-10-30 054733.png " alt="COVID-19 SARIMA Forecast" width="600" height="300">
    <p>In this graph, the seasonality aspect can be seen in the graph itself by the data appearing to be more impacted in the forecast. Then, the results tab will go over how the RSME compares with each other.</p>
</body>
</html>

<h3>Bayesian Structural Time Series Model (BSTS)</h3>
<p>The BSTS model can now be expressed as:</p>
<p>\[
Y_t = \phi_t + \Phi_t + X_t \beta + \epsilon_t
\]</p>

<p>Where:</p>
<ul>
  <li>\( Y_t \): The observed value of the time series at time \( t \) (the confirmed COVID-19 cases in Florida).</li>
  <li>\( \phi_t \): The trend component capturing the overall movement in the COVID-19 cases over time.</li>
  <li>\( \Phi_t \): The seasonal component, accounting for recurring patterns (e.g., weekly increases in COVID-19 cases).</li>
  <li>\( X_t \): External regressors such as public policies, mobility data, or vaccination rates.</li>
  <li>\( \beta \): A vector of regression coefficients corresponding to the regressors.</li>
  <li>\( \epsilon_t \): Error term at time \( t \), accounting for random noise.</li>
</ul>
<p><strong>edit me</strong></p>
    
 <h2>Methods for CO₂ Emission Forecasting</h2>
<p>In this part of my methodology, I will explain the following: the data cleaning process for the NOAA dataset, the development and application of the ARIMA/SARIMA model on this dataset, and finally, the BSTS model. These models will be compared in a later section of the capstone to evaluate their performance on this dataset.</p>

<h3>Data Cleaning</h3>
<p>I downloaded the Mauna Loa CO₂ dataset from the NOAA website (<a href="https://gml.noaa.gov/ccgg/trends/">Mauna Loa CO₂ Data</a>) because of its reliability and regular updates, which makes it perfect for time series forecasting. However, before I could use the data, I had perform some data preparations. At the top of the file, there was a description about the data and how it should be used, but it got read as part of the dataset, which messed up the column headers. I had to delete that section to get everything aligned correctly. The dataset also mentioned some missing days, which could throw off the averages if not handled carefully. This part was important to keep the data unbiased. Another issue was the gap caused by the Mauna Loa volcano eruption, which stopped data collection from November 29, 2022, to July 2023. I had to account for this gap during my analysis so it wouldn’t affect my results. Lastly, the data didn't have separate "Year" and "Month" columns, even though the information was included in the decimal date field. To make things easier to work with, I added those columns by extracting the year and month from the decimal dates. After these adjustments, the dataset was ready for analysis.</p>

<h3>ARIMA/SARIMA Method:</h3>
<p>To forecast CO₂ emissions, we first download the dataset from the NOAA Global Monitoring Laboratory website, where they monitor monthly CO₂ emissions at Mauna Loa. After downloading the dataset, I loaded it into a Jupyter Notebook for graphing and exploration.</p>
<p>Initially, the graph of the CO₂ data showed both a seasonal pattern and an upward trend, suggesting that the data is non-stationary. To confirm this, I applied the Augmented Dickey-Fuller (ADF) test, which tests the following hypotheses:</p>

<ul>
    <li><strong>H0:</strong> The data is non-stationary.</li>
    <li><strong>H1:</strong> The data is stationary.</li>
</ul>

<p>Using a significance level of 0.05, if the p-value is less than 0.05, we reject the null hypothesis. In this case, the p-value from the ADF test was 1, which is greater than 0.05. This indicates that the data is non-stationary, and stationarization is required.After applying the differencing technique to the data, the Augmented Dickey-Fuller (ADF) test was re-conducted. The resulting p-value of 0.00005 provides strong evidence to reject the null hypothesis (\(H_0\)), confirming that the series is now stationary (\(p < 0.05\)).Next, I examined the Partial Autocorrelation Function (PACF) and Autocorrelation Function (ACF) plots derived from the differenced data. Based on these plots, two potential ARIMA models were identified: (3,1,2) and (3,1,1). I used Python's Statsmodels library to fit these models and selected the model with the lowest Akaike Information Criterion (AIC) value, which turned out to be the (3,1,2) model. This model was then used to forecast CO₂ emissions up to 2025. While the forecast captured the general upward trend, it did not represent the seasonality in the data.</p>
<p>To address the seasonality, I applied a Seasonal ARIMA (SARIMA) model. Using the same non-seasonal order (3,1,2), I added a seasonal order of (1,1,12) to account for the monthly seasonality. After fitting the SARIMA model and forecasting 60 steps ahead, the resulting forecast captured both the trend and the seasonality of the data, providing a more accurate projection.</p>
<p>Given the specified parameters from the AIC model, (3,1,2), it is now possible to mathematically represent our ARIMA model with the following:</p>
<p>\[Y_t = c + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \phi_3 Y_{t-3} + \theta_1 \epsilon_{t-1} + \theta_2 \epsilon_{t-2} + \epsilon_t\]</p>
<p>Where:</p>
<ul>
  <li>\( Y_t \): The value of the CO₂ emissions at time \( t \).</li>
  <li>\( c \): Constant term (intercept).</li>
  <li>\( \phi_i \) (\( i = 1, 2, 3 \)): Coefficients for the Auto-Regressive (AR) terms (from lag 1 to lag 3).</li>
  <li>\( Y_{t-i} \): The value of the time series at previous time steps (\( t-1, t-2, t-3 \)).</li>
  <li>\( \theta_i \) (\( i = 1, 2 \)): Coefficients for the Moving Average (MA) terms (past errors).</li>
  <li>\( \epsilon_{t-i} \): Errors at previous time steps (\( t-1, t-2 \)).</li>
  <li>\( \epsilon_t \): Error term at time \( t \).</li>
</ul>
<p>The AR part includes three lags,\phi_1, \phi_2, \phi_3. And the MA part containes two past errors, \theta_1, \theta_2. Then, the differencing allowed there to be an impact on the \(d\) term.  </p>

<p>Now, this ARIMA model, perhaps due to this dataset being significantly smaller, has not captured the seasonality as appropriately. This will be continued to be explored in the results tab. However, this is why it is important to consider the SARIMA in this case as well.</p>
<p>To address the seasonality, I applied a Seasonal ARIMA (SARIMA) model. Using the same non-seasonal order (3,1,2), I added a seasonal order of (1,1,12) to account for the monthly seasonality. After fitting the SARIMA model and forecasting 60 steps ahead, the resulting forecast captured both the trend and the seasonality of the data, providing a more accurate projection.</p>

<h3>Bayesian STS Methods:</h3>
<p>After the general data cleaning as referenced above, I originally attempted to use the PyMC3 library, but it was outdated. Instead, I used PyMC and TensorFlow Probability (TFP), both of which support Bayesian modeling methods. TFP offers a lower-level API but requires additional shape handling, as seen in the code through the use of .numpy() and .squeeze() when defining the time series model.</p>
    <pre><code>
    file_path = r"C:\Users\gesua\Documents\Capstone_Project\Capstone\co2_mm_mlo.csv"
    co2_data = pd.read_csv(file_path)
    co2_data.rename(columns={'year': 'year', 'date_month': 'month'}, inplace=True)
    co2_data['date'] = pd.to_datetime(co2_data[['year', 'month']].assign(day=1))
    </code></pre>
<p>This code emphasizes the data cleaning process. After importing, the columns are renamed to <code>year</code>, <code>month</code>, and <code>date</code> for consistency. Then, the data is processed into a datetime format, which enables easy plotting of atmospheric CO2 levels over the years.</p>
    <img src="images/Screenshot 2024-10-27 051935.png" alt="Graph of atmospheric CO2 levels over the years">
<p>The graph visualizes the seasonality pattern alongside the trend across the time series data. The seasonality is represented by the periodic shifts seen diagonally, indicating repeating monthly cycles (e.g., January through December). This diagonal pattern emerges from transforming the time data into a cyclic sequence, such as [1, 2, 3, ..., 12, 1, 2, ...]. In the design matrix, these cycles become evident, helping capture recurring patterns year-over-year.</p> <p>The trend component, on the other hand, models the general direction of the data over time, reflecting the increase in CO2 levels. By combining the seasonal pattern with the trend, this visualization lays the foundation for the time series regression model. Specifically, in the code, the dummy variables capture these seasonal effects, and the relationship is modeled using a linear regression framework with a likelihood of \(Y \sim N(X\beta, \sigma^2)\). As part of the Bayesian model, Gaussian priors are incorporated, allowing for more robust inference as the model develops.</p>
    <img src="images/Screenshot 2024-10-27 051948.png " alt="Graph of Seasonality and Trend of the Data">
<p>After the visualizations, I used the prior predictive samples from the simple regression model as graphed in the beginning. Aith this, we now define the following function in python: </p>
    <pre><code>intercept = yield root(tfd.Normal(0., 100., name="intercept"))</code></pre>
  <p>This represents the intercept baseline of the time series, where we are modeling with the Gaussian prior, centered at 0 with a large standard deviation (in this case, 100) to allow flexibility within the timeseries. Because I do not have previous knowledge on the timeseries, I am attempting to make a model that is flexible that will cover the data. </p>
    <pre><code>trend_coeff = yield root(tfd.Normal(0., 10., name="trend_coeff"))
    seasonality_coeff = yield root(tfd.Sample(tfd.Normal(0., 1.), sample_shape=seasonality.shape[-1], name="seasonality_coeff"))
    noise = yield root(tfd.HalfCauchy(loc=0., scale=5., name="noise_sigma"))
    </code></pre>
  <p>This code is capturing the seasonality, trend, applying shape and structure to the model definiton. The <code>sample_shape</code> is applying the 12 month seasonality, and the Half-Cauchy distribution is accounting for the noise, or randomness of the data. This also is ensuring that the variance remains positive.</p>
  <p>After this, the observed likelihood is defined with the normal distribution with an ensured independence in the observations. This is implimented with <code>tfd.independent</code>.</p>
  <p>Next, sampling the priors can be seen with the graph below. </p>
    <img src="images/Screenshot 2024-10-27 052001.png " alt="Graph of Priors">
  <p>Prior predictive samples from the simple regression model for the monthly CO2. Each line is one simulated time series, and they were uninformative priors, as they did not stem from the data set originally, but were applied general priors to follow with Gaussian distribution and are pre-defined parameters.</p>
  <p>Next, I developed code for the actual forecast. Which can be highlighted with the following code: </p>
<pre><code> train_end_date = '2023-12'
co2_training_data = co2_data.loc[:train_end_date, 'Monthly Average of CO2'].values.astype(np.float32)
dates_train = co2_data.index[:len(co2_training_data)]
co2_testing_data = co2_data.loc['2024-01':'2024-09', 'Monthly Average of CO2'].values.astype(np.float32)
dates_test = co2_data.index[len(co2_training_data):len(co2_training_data) + len(co2_testing_data)]
</code></pre>
  <p>First, I have to prepare the training and test data. To summarize, training data is going to be the data that is used to highlight the historical data, and the testing data is defining the timeframe from January 2024 to September 2024. These dates are important since I am applying hold-out MAPE to compare optimization of the model.</p>
<pre><code>model = sts.Sum(
    components=[
        sts.LocalLinearTrend(observed_time_series=co2_training_data),
        sts.Seasonal(num_seasons=12, observed_time_series=co2_training_data)
  ],
    observed_time_series=co2_training_data)
</code></pre> 
<p>This code defines the BSTS model, seen by the LocalLinearTrend and the seasonal component. Since this is monthly data, there is a seasonality of 12 months to model the dataset. These two help the model to stretch the forecast into the future as it highlights the long-term trends and the seasonality variations.</p>

<pre><code> variational_posteriors = tfp.sts.build_factored_surrogate_posterior(model=model)
optimizer = tf.optimizers.Adam(learning_rate=0.1)
tfp.vi.fit_surrogate_posterior(
    target_log_prob_fn=model.joint_log_prob(co2_training_data),
    surrogate_posterior=variational_posteriors,
    optimizer=optimizer,
    num_steps=200
)
</code></pre>
<p>Variational surrogate posterior (or also known as Variational Inference) is used to cast an approximation on Bayesian inference for optimization. This shows the power of the TensorFlow Probability library as it seeking a 'surrogate' posterior and minimizes the KL divergence. In my code, it is approximating the posterior distribution of the model parameters. Then, using the Adam optimizer is being used to find the "best-fit" parameters.</p>
<pre><code> forecast_dist = tfp.sts.forecast
  (
    model=model,
    observed_time_series=co2_training_data,
    parameter_samples=variational_posteriors.sample(50),
    num_steps_forecast=9
  )
forecast_mean = forecast_dist.mean().numpy().squeeze()
forecast_index = pd.date_range(dates_train[-1] + pd.DateOffset(months=1), periods=9, freq="M")
 </code></pre>
  <p>Finally, I am able to now forecast the next 9 months using the posterior samples that came from the VI, and thden generates the mean forecast and dates for the future months. After this, the following data was plotted and the outcome shows that the model predictions match the actual date of the data. </p>
  <img src="images/Screenshot 2024-10-27 052017.png" alt="Graph of Priors">
  </div>  

<!-- Tab content for Results -->
<div id="Results" class="tabcontent">
  <h2>Results</h2>
  <h3>COVID-19</h3>
  <p>In this section, I will review the COVID-19 dataset using ARIMA, SARIMA, and BSTS models to evaluate the forecasted trends and key results.</p>
  <p><strong> ADD FORECASTING IMAGE HERE</strong></p>
  <iframe src="tables/covid_results_table.html" width="100%" height="200" frameborder="0"></iframe>

  <h3>CO2 Emmissions</h3>
  <p>In this section, I will review the NOAA dataset using ARIMA, SARIMA, and BSTS models to evaluate the forecasted trends and key results.</p>
  <img src="images/Screenshot 2024-10-29 052810.png" alt="ARIMA Forecast CO2">
  <p>The original pattern and the forecasted are represented in blue (original) and forecasted (red). The original model was seen to trend upwards, and we can see that the forecasted is also prejected to follow the dame trend. This indicates to us that there is a continued increase in CO₂ emissions. There is a variate in the seasonal projections, as they have become less profound as the forecast extends into the future. This ARIMA model is suggesting that although CO₂ levels are projected to continue to rise, the seasonality may become less impactful over time. This seasonality is seen differently when looking at the SARIMA model. This model does seem to capture the historical seasonality and upward trend. </p>
  <img src="images/Screenshot 2024-10-29 052822.png" alt="SARIMA Forecast CO2">
  <p>Now, when analyzing the RMSE, comparing the fact that the RMSE of ARIMA and the SARIMA where slightly different, it is important to note that this minor difference could indicate a difference in model performance, perhaps favoring the ARIMA model. However, both of the values were significant in the sense that the lower a RMSE value is, the more fitted the model appears with the data. This is important since it shows that the data is being captured well. </p><p>One of the key limitations with both ARIMA and SARIMA models is how they handle abrupt shifts and irregularities. As mentioned earlier, the dataset includes a period impacted by a volcanic eruption, which may have disrupted the data and affected how the models generate forecasts. This irregularity could skew the results, as the models rely on consistent patterns for accuracy. Additionally, while SARIMA accounts for seasonality, making it better suited for cyclical trends, that added complexity can introduce more noise into the model. This added noise might explain the slightly higher RMSE observed in the SARIMA model compared to ARIMA, as the increased complexity can lead to less precise predictions.</p>
  <iframe src="tables/co2_results_table.html" width="100%" height="200" frameborder="0"></iframe>
  <img src="images/Screenshot 2024-10-27 052017.png " alt="training data, forecast, actual data graph">
  <p></p>

<h3>Discussion</h3>
<p>The Bayesian model emerged as the stronger performer across these datasets, though it comes with some challenges. One significant drawback is that it is computationally expensive and takes a long time to load and process data, which can be frustrating during model development.</p>
<p>Both datasets used in this study were non-stationary, and the way this was handled differs between ARIMA and Bayesian Structural Time Series (BSTS) models. I suspect that this difference may have contributed to ARIMA's suboptimal performance. It raises the question of how ARIMA would have performed had the data been transformed differently or more thoroughly stationarized before modeling.</p>
<p>Looking ahead, it would be interesting to explore how the results might change by incorporating more informed priors into the Bayesian model. This could improve the model's predictive power and provide more meaningful insights.</p>
<p>While ARIMA is simpler to understand and easier to implement, careful model selection remains crucial. With large datasets, relying on automatic parameter selection (like Statsmodels' choice of (p, d, q)) may not always yield the most efficient or effective results, which highlights the importance of thoughtful tuning and testing in the modeling process.</p>

</div>

<!-- Tab content for Presentation -->
<div id="Presentation" class="tabcontent">
<h3>Project Presentation</h3>
<iframe src="https://docs.google.com/presentation/d/1p9K4MnN0rtTCU8AaNiB7_Ls5CaqFusIwrpHZvxcyB_k/embed?start=false&loop=false&delayms=3000" 
        frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>
</div>
<!-- Tab content for References -->
<div id="References" class="tabcontent">
  <h2>References and Code</h2>
<ul>
    <li><strong>[1] Kulshreshtha, Vikas, and N. K. Garg. 2020.</strong> "Predicting the New Cases of Coronavirus [COVID-19] in India by Using Time Series Analysis as Machine Learning Model in Python." <em>The Institution of Engineers (India)</em>.</li>
    <li><strong>[2] Demongeot J, Oshinubi K, Rachdi M, et al. 2021.</strong> "The Application of ARIMA Model to Analyze COVID-19 Incidence Pattern in Several Countries." <em>Journal of Mathematics and Computer Science</em>.</li>
    <li><strong>[3] Wang, Yanding, et al. 2022.</strong> "Prediction and Analysis of COVID-19 Daily New Cases and Cumulative Cases: Time Series Forecasting and Machine Learning Models." <em>BMC Infectious Diseases</em>, vol. 22, p. 495.</li>
    <li><strong>[4] Fotia, Pasquale, and Massimiliano Ferrara. 2023.</strong> "A Different Approach for Causal Impact Analysis on Python with Bayesian Structural Time-Series and Bidirectional LSTM Models." <em>Atti della Accademia Peloritana dei Pericolanti</em>.</li>
    <li><strong>[5] Nielsen, Michael. 2015.</strong> <em>Neural Networks and Deep Learning</em>. Determination Press.</li>
    <li><strong>[6] Ning, Yanrui, Hossein Kazemi, and Pejman Tahmasebi. 2022.</strong> "A Comparative Machine Learning Study for Time Series Oil Production Forecasting: ARIMA, LSTM, and Prophet." <em>Computers & Geosciences</em>, vol. 164, 105126.</li>
    <li><strong>[7] Tinungki, G.M. 2019.</strong> "The Analysis of Partial Autocorrelation Function in Predicting Maximum Wind Speed." <em>IOP Conference Series: Earth and Environmental Science</em>, vol. 235, 012097. <a href="https://doi.org/10.1088/1755-1315/235/1/012097">https://doi.org/10.1088/1755-1315/235/1/012097</a>.</li>
    <li><strong>[8] Psychology Learning & Teaching, 2020.</strong> "The Importance of Cross-Validation in Time Series Forecasting and Bayesian Inference." <em>Psychology Learning & Teaching</em>, vol. 19(1), 21–35. <a href="https://doi.org/10.1177/1475725719874542">https://doi.org/10.1177/1475725719874542</a>.</li>
    <li><strong>[9] Nature, 2020.</strong> <a href="https://www.nature.com/articles/s43586-020-00001-2" target="_blank">https://www.nature.com/articles/s43586-020-00001-2</a>.</li>
    <li><strong>[10] Thorakkattle, Muhammed Navas, et al. 2022.</strong> "Forecasting the Trends of Covid-19 and Causal Impact of Vaccines Using Bayesian Structural Time Series and ARIMA." <em>Annals of Data Science</em>, vol. 9(5), 1025–1047. <a href="https://doi.org/10.1007/s40745-022-00418-4">https://doi.org/10.1007/s40745-022-00418-4</a>.</li>
    <li><strong>[11] ResearchGate, 2021.</strong> "Examples for Stationary and Non-Stationary Time Series." <a href="https://www.researchgate.net/publication/348592737/figure/fig3/AS:981645804970018@1611054006754/Examples-for-stationary-and-non-stationary-time-series.png" target="_blank">https://www.researchgate.net/publication/348592737/figure/fig3/AS:981645804970018@1611054006754/Examples-for-stationary-and-non-stationary-time-series.png</a>.</li>
</ul>
  <h2>ARIMA/SARIMA full code</h2>
  <iframe width="900" height="600" frameborder="0"
        src="https://nbviewer.org/github/GianyceG/gianyceg.github.io/blob/main/COVID19DataARIMAandSARIMA.html"></iframe>
  <iframe width="900" height="600" frameborder="0" 
        src="https://nbviewer.org/github/GianyceG/gianyceg.github.io/blob/main/CO2_ARIMA_and_SARIMA.ipynb"></iframe>
  
<h2>Bayesian STS Code</h2>
<iframe width="900" height="600" frameborder="0" 
    src="https://nbviewer.org/github/GianyceG/gianyceg.github.io/blob/main/CO2_Bayesian_Code.ipynb">
</iframe>

</div>


   <!-- JavaScript to handle tab switching -->
  <script>
    function openTab(evt, tabName) {
      var i, tabcontent, tablinks;
      tabcontent = document.getElementsByClassName("tabcontent");
      for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
      }
      tablinks = document.getElementsByClassName("tablinks");
      for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
      }
      document.getElementById(tabName).style.display = "block";
      evt.currentTarget.className += " active";
    }

    // Open the default tab
    document.getElementById("defaultOpen").click();

    // Force MathJax to render any LaTeX
    MathJax.typeset();
  </script>

</body>
</html>
